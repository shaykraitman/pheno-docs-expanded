{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "output-file: 027-voice.html\n",
    "title: Voice Recording\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This dataset consists of high-quality voice recordings collected from participants in a controlled clinical research setting. Each participant provided a ~30-second sustained counting sample (in Hebrew, with a subset in Japanese), recorded using a cardioid dynamic USB/XLR microphone and Audacity software. Recordings are stored in lossless `.flac` format to preserve full audio fidelity, accompanied by participant metadata (Participant ID, sex, date of birth) in a structured `.csv` file.\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Voice data is increasingly being used in clinical research and personalized medicine. Key trends include using vocal biomarkers for disease diagnosis (e.g., Parkinson's, Alzheimer's), mental health assessment, and monitoring respiratory conditions. Additionally, voice-based technologies are being developed for treatment adherence, remote monitoring, and personalized voice assistants in healthcare. Voice data is also explored for emotion recognition and speech therapy applications. Overall, voice data has the potential to transform healthcare by providing non-invasive, cost-effective, and convenient diagnostic and treatment methods.\n",
    "\n",
    "In the context of voice, a **vocal biomarker** is a signature, a feature, or a combination of features from the audio signal of the voice that is associated with a clinical outcome and can be used to monitor patients, diagnose a condition, or grade the severity or the stages of a disease or for drug development.\n",
    "\n",
    "Work on vocal biomarkers has mainly been performed in the field of neurodegenerative disorders, particularly Parkinson's disease, where voice disorders are very frequent (as high as 70-80%) and where voice changes are expected to be utilized as an early diagnostic biomarker. Other areas of research include mental health and monitoring emotions, multiple sclerosis and rheumatoid arthritis, Alzheimer's disease and mild cognitive impairment, cardiometabolic and cardiovascular diseases, and COVID-19 and other conditions with lung and respiratory symptoms.\n",
    "\n",
    "### Measurement protocol \n",
    "<!-- long measurment protocol for the data browser -->\n",
    "\n",
    "The participant's voice is audio-recorded for around thirty (30) seconds by counting to thirty (30) in their native language (primarily Hebrew, with a subset in Japanese).\n",
    "\n",
    "#### Device and Software\n",
    "\n",
    "**Device type:** Cardioid dynamic USB/XLR microphone  \n",
    "**Software:** Audacity (open-source audio recording/editing software)  \n",
    "**Recording format:** Lossless `.flac` (primary), `.wav` supported  \n",
    "**Recording duration:** ~30 seconds (counting 1–30)  \n",
    "**Recording environment:** Quiet, controlled clinical setting\n",
    "\n",
    "#### Device Specifications\n",
    "\n",
    "| Parameter | Specification |\n",
    "|-----------|---------------|\n",
    "| Device type | Cardioid dynamic USB/XLR microphone |\n",
    "| Polar pattern | Cardioid (unidirectional) |\n",
    "| Connection type | USB-C / XLR |\n",
    "| Sampling rate | 44.1 kHz (default), supports up to 48 kHz |\n",
    "| Bit depth | 16-bit / 24-bit |\n",
    "| Frequency response | 50 Hz – 15 kHz |\n",
    "| Microphone sensitivity | -55 dBV/Pa (at 1 kHz) |\n",
    "| Recording environment | Quiet, controlled clinical setting |\n",
    "| Contraindications / limitations | Avoid high background noise; maintain fixed mic distance (15–30 cm) from mouth |\n",
    "| Accessories used | Desktop mic stand, pop filter |\n",
    "\n",
    "### Data availability \n",
    "<!-- for the example notebooks -->\n",
    "\n",
    "The information is stored as individual audio files in `.flac` format (lossless compression), with associated metadata in `.csv` files. Each recording is approximately 30 seconds in duration.\n",
    "\n",
    "### Summary of available data \n",
    "<!-- for the data browser -->\n",
    "\n",
    "**Voice recordings:** High-dimensional time-series data captured as audio recordings (`.flac` format), obtained by participants counting to thirty (30) in Hebrew (with a subset in Japanese). The `.flac` format retains full audio quality (lossless) and is preferred for clinical signal fidelity.\n",
    "\n",
    "The dataset includes:\n",
    "- Audio recordings in lossless `.flac` format\n",
    "- Participant metadata (ID, sex, date of birth)\n",
    "- Recording metadata (date, duration, language)\n",
    "\n",
    "As of the current release, the dataset contains 9,246 Hebrew-speaking participants with an ongoing subset of Japanese-language recordings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Voice data is increasingly being used in clinical research and personalized medicine. Key trends include using vocal biomarkers for disease diagnosis (e.g., Parkinson's, Alzheimer's), mental health assessment, and monitoring respiratory conditions. Additionally, voice-based technologies are being developed for treatment adherence, remote monitoring, and personalized voice assistants in healthcare. Voice data is also explored for emotion recognition and speech therapy applications. Overall, voice data has the potential to transform healthcare by providing non-invasive, cost-effective, and convenient diagnostic and treatment methods.\n",
    "\n",
    "In the context of voice, a **vocal biomarker** is a signature, a feature, or a combination of features from the audio signal of the voice that is associated with a clinical outcome and can be used to monitor patients, diagnose a condition, or grade the severity or the stages of a disease or for drug development.\n",
    "\n",
    "Work on vocal biomarkers has mainly been performed in the field of neurodegenerative disorders, particularly Parkinson's disease, where voice disorders are very frequent (as high as 70-80%) and where voice changes are expected to be utilized as an early diagnostic biomarker.\n",
    "\n",
    "#### Areas of research\n",
    "- Mental Health and Monitoring Emotions\n",
    "- Multiple Sclerosis and Rheumatoid Arthritis\n",
    "- Alzheimer's Disease and Mild Cognitive Impairment\n",
    "- Cardiometabolic and Cardiovascular Diseases\n",
    "- COVID-19 and Other Conditions with Lung and Respiratory Symptoms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement protocol\n",
    "\n",
    "The participant's voice is audio-recorded for around thirty (30) seconds by counting to thirty (30) in their native language (primarily Hebrew, with a subset in Japanese).\n",
    "\n",
    "#### Device and Software\n",
    "\n",
    "**Device type:** Cardioid dynamic USB/XLR microphone  \n",
    "**Software:** Audacity (open-source audio recording/editing software)  \n",
    "**Recording format:** Lossless `.flac` (primary), `.wav` supported  \n",
    "**Recording duration:** ~30 seconds (counting 1–30)  \n",
    "**Recording environment:** Quiet, controlled clinical setting\n",
    "\n",
    "#### Device Specifications\n",
    "\n",
    "| Parameter | Specification |\n",
    "|-----------|---------------|\n",
    "| Device type | Cardioid dynamic USB/XLR microphone |\n",
    "| Polar pattern | Cardioid (unidirectional) |\n",
    "| Connection type | USB-C / XLR |\n",
    "| Sampling rate | 44.1 kHz (default), supports up to 48 kHz |\n",
    "| Bit depth | 16-bit / 24-bit |\n",
    "| Frequency response | 50 Hz – 15 kHz |\n",
    "| Microphone sensitivity | -55 dBV/Pa (at 1 kHz) |\n",
    "| Recording environment | Quiet, controlled clinical setting |\n",
    "| Contraindications / limitations | Avoid high background noise; maintain fixed mic distance (15–30 cm) from mouth |\n",
    "| Accessories used | Desktop mic stand, pop filter |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data availability\n",
    "\n",
    "The data comprises two levels of processing:\n",
    "\n",
    "1. **Voice recordings:** High-dimensional time-series data captured as audio recordings (`.flac` format), obtained by participants counting to thirty (30) in Hebrew. The `.flac` format retains full audio quality (lossless) and is preferred for clinical signal fidelity.\n",
    "\n",
    "2. **Associated metadata:** A structured `.csv` file containing participant-level information, including Participant ID, Sex, and Date of Birth (DOB).\n",
    "\n",
    "**Total participants:** 9,246 (including a few Japanese-speaking participants)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of available data\n",
    "\n",
    "#### Raw Data\n",
    "- **Voice recordings:** Lossless `.flac` audio files containing ~30 seconds of counting\n",
    "- **Metadata:** CSV file with participant ID, sex, and date of birth\n",
    "\n",
    "#### Info on our raw data\n",
    "\n",
    "A `.flac` or `.wav` file stores audio data using lossless compression, retaining all original information. When loaded using Librosa with the `sr` (sampling-rate) parameter set to `None`, it decompresses the audio data and converts it into a NumPy array without resampling. This array represents the waveform, where each element is the amplitude of the audio signal at a specific point in time.\n",
    "\n",
    "Digital audio data is processed using specialized libraries like Librosa, Praat, OpenSmile (Traditional medical and signal-based features - current version V1.0), and Wav2Vec (deep learning based features - next version V2.0) for feature extraction, signal processing, and visualization.\n",
    "\n",
    "#### Useful Python Packages\n",
    "- **Librosa:** Traditional signal processing and feature extraction tool\n",
    "- **Praat:** Clinical linguistic feature extraction tool\n",
    "- **OpenSmile:** Audio feature extraction\n",
    "- **BlaBla:** Clinical linguistic feature extraction tool\n",
    "- **Wav2Vec2:** Deep learning network for feature extraction (V2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "#### 1. Traditional Signal Processing–Based Features (Clinical Relevant): V1.0\n",
    "\n",
    "Acoustic features offer an objective way to quantify speech patterns that may be altered in clinical populations. Below are the key features extracted:\n",
    "\n",
    "##### Fundamental Frequency (F0)\n",
    "- Captures the basic pitch (lowest frequency) of vocal fold vibration\n",
    "- Reflects both physiological voice-production characteristics and prosodic patterns\n",
    "- In schizophrenia, there's consistently reduced pitch variability and monotonous prosody, tied to blunted affect\n",
    "- F0 is increasingly considered a candidate vocal biomarker for schizophrenia\n",
    "\n",
    "##### Formants (F1 – F3)\n",
    "- Formants are resonant frequencies shaped by vocal tract and articulator positions, notably tongue and jaw\n",
    "- Altered formant patterns suggest imprecise articulation, motor planning deficits, and cognitive planning issues in schizophrenia\n",
    "- Clinical relevance lies in the ratios and distances between F1, F2, and F3, which reflect vocal tract configuration and motor function\n",
    "\n",
    "##### Harmonics-to-Noise Ratio (HNR)\n",
    "- Quantifies the ratio of periodic (harmonic) vs. aperiodic (noise) components in voice\n",
    "- Lower HNR indicates breathiness, roughness, or dysphonia—commonly seen in schizophrenia\n",
    "- Objective measures like HNR help reduce subjectivity in clinical voice evaluation\n",
    "\n",
    "##### Jitter\n",
    "- Reflects cycle-to-cycle variation in pitch (frequency perturbation)\n",
    "- Elevated jitter indicates irregular laryngeal control and reduced neuromotor precision\n",
    "- Normative range: <0.5% for adults\n",
    "\n",
    "##### Shimmer\n",
    "- Captures cycle-to-cycle variation in amplitude (amplitude perturbation)\n",
    "- Higher shimmer signals reduced fine motor control in vocal folds\n",
    "- Clinically associated with changes in glottal resistance and vocal roughness\n",
    "\n",
    "##### Amplitude (Intensity)\n",
    "- Represents loudness dynamics—driven by respiratory support and communicative intent\n",
    "- Reduced amplitude modulation often manifests in conditions like schizophrenia, congruent with negative symptoms like flat affect\n",
    "\n",
    "##### Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "- Compact spectral descriptors aligned with human auditory perception\n",
    "- Encode both low-frequency spectral envelope and higher-frequency details\n",
    "- In schizophrenia studies:\n",
    "  - Support discrimination from healthy controls (accuracy ~82%)\n",
    "  - Achieve very high diagnostic performance (accuracy 91.7%, ROC‑AUC ≈ 0.963) when combined with mel‑spectrograms\n",
    "  - In multimodal approaches (speech + video), combining MFCCs with vocal tract features boosted detection by ~18%\n",
    "\n",
    "##### Spectrogram\n",
    "- Time-frequency representation of the audio signal\n",
    "- Log-mel spectrograms, often used in deep learning pipelines, enhance differentiation of schizophrenia in speech\n",
    "- Can serve as input \"images\" to vision-based models (e.g., convolutional neural networks)\n",
    "\n",
    "**Tools/Models:** OpenSMILE, Praat, Librosa  \n",
    "**Clinical Use:** Jitter, shimmer, HNR; mood and fatigue disorders often alter pitch dynamics, shimmer, and jitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Additional Non-Clinical Signal Features (Time and Frequency Domain): V1.0\n",
    "\n",
    "- **Duration:** Total length of the audio signal (seconds)\n",
    "- **Sample Rate:** Number of audio samples captured per second (Hz)\n",
    "- **Number of Samples:** Total count of individual audio samples in the signal\n",
    "- **Number of Channels:** Distinct audio channels (e.g., mono, stereo)\n",
    "- **Bit Depth:** Bits used to represent each audio sample (affects resolution)\n",
    "- **Number of Frames:** Total frames, each containing one sample per channel\n",
    "- **Spectral Centroid:** \"Center of mass\" of the spectrum (brightness)\n",
    "- **Spectral Rolloff:** Frequency below which a set percentage of spectral energy is contained\n",
    "- **Spectral Bandwidth:** Width of the frequency band with most energy\n",
    "- **Spectral Contrast:** Difference in energy between peaks and valleys of the spectrum\n",
    "- **Spectral Flatness:** How noise-like (flat) or tone-like (peaky) the spectrum is\n",
    "- **Zero Crossing Rate:** Rate at which the signal changes sign (related to noisiness)\n",
    "- **RMS Energy:** Root mean square energy (perceived loudness)\n",
    "- **Tempo:** Estimated beats per minute (BPM)\n",
    "- **Chroma:** Distribution of energy across the 12 pitch classes of the octave\n",
    "  - Chroma Mean: Average chroma values over time\n",
    "  - Chroma Std: Standard deviation of chroma values (variability)\n",
    "- **Tonnetz:** Tonal relationships in music based on harmonic intervals\n",
    "  - Tonnetz Mean: Average tonal relationship values over time\n",
    "  - Tonnetz Std: Standard deviation of tonal relationship values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Foundational Model / Deep Learning–Based Features (Further Research Required): V2.0\n",
    "\n",
    "##### Model-Based SSL Embeddings\n",
    "- **Models:** wav2vec 2.0, WavLM, XLS-R, HuBERT\n",
    "- **Clinical Use:** Encode broad vocal-tract information (generic)\n",
    "\n",
    "##### Speaker & Diarisation Vectors\n",
    "- **Models:** x-vector\n",
    "- **Clinical Use:** Capture subtle vocal-tract/breathing habits; shown best performance for male sleep apnoea in research\n",
    "\n",
    "##### Affect / Prosody Models\n",
    "- **Models:** wav2vec2-SER, WavLM-SED\n",
    "- **Clinical Use:** Mood and fatigue disorders often alter pitch dynamics and shimmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality and Sanitation\n",
    "\n",
    "Quality control for voice data focuses on ensuring clean, analyzable recordings with minimal artifacts. All incoming audio undergoes automated checks to identify and flag recordings with:\n",
    "\n",
    "- Silence or low-signal segments exceeding a defined threshold (e.g., >30% of duration)\n",
    "- Excessive background noise based on spectral flatness, zero-crossing rate, and SNR measures (V2.0)\n",
    "- Clipping or distortion caused by over-amplification\n",
    "- Out-of-bounds acoustic values (e.g., pitch range outside human norms)\n",
    "\n",
    "QC status is stored in metadata, and failed recordings are reviewed for possible re-recording or exclusion from downstream analysis.\n",
    "\n",
    "**Note:** There aren't any set QC protocols for voice signal processing. We are developing signal quality and status measurements with the help of existing features, including methods to find silence in audio signals, out-of-bounds values, extreme noise, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association with Clinical Factors\n",
    "\n",
    "Current research in voice recordings related to health has shown associations between voice features and various health conditions:\n",
    "\n",
    "- **Aging:** Voice features, such as fundamental frequency, formants, and jitter, have been found to change with age, reflecting physiological changes in the vocal tract and larynx.\n",
    "\n",
    "- **Emotional state:** Voice features, such as pitch, intensity, and speech rate, can be used to detect and differentiate various emotional states (e.g., happiness, sadness, anger, fear).\n",
    "\n",
    "- **Neurological disorders:** Voice features, such as pitch variability, irregular phonation, and speech rate, have been used to detect and monitor neurological disorders like Parkinson's disease, Alzheimer's disease, and multiple sclerosis.\n",
    "\n",
    "- **Psychiatric disorders:** Voice features have been used to detect and monitor psychiatric disorders such as depression, anxiety, bipolar disorder, and schizophrenia. This may include changes in prosody, speech rate, or other acoustic features.\n",
    "\n",
    "- **Vocal fatigue:** Voice features, such as jitter, shimmer, and harmonics-to-noise ratio, can be used to assess vocal fatigue and monitor the vocal health of professional voice users like singers, actors, and teachers.\n",
    "\n",
    "- **Respiratory disorders:** Voice features, such as breathiness, pitch variability, and speech rate, have been used to detect and monitor respiratory disorders like asthma, chronic obstructive pulmonary disease (COPD), and laryngeal disorders.\n",
    "\n",
    "- **Speech disorders:** Voice features, such as formants, pitch, and speech rate, have been used to detect and monitor speech disorders like stuttering, cluttering, and speech sound disorders.\n",
    "\n",
    "- **Language identification:** Voice features, such as MFCCs, formants, and pitch, have been used to identify the language spoken by an individual or to detect accents and dialects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant links\n",
    "\n",
    "* [Pheno Knowledgebase](https://knowledgebase.pheno.ai/)\n",
    "* [Pheno Data Browser](https://pheno-demo-app.vercel.app/)\n",
    "\n",
    "### References\n",
    "\n",
    "- Survey On Biomarkers In Human Vocalizations - arXiv\n",
    "- Neurological Voice Disorders: A Review, Tiffany V Wang, Phillip C Song\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
